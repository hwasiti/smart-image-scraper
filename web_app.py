import os
from io import StringIO
import streamlit as st
import pymongo
import pandas as pd
import numpy as np
from cryptography.fernet import Fernet
from PIL import Image
from math import floor, ceil
import pydeck as pdk


def decrypt(token: bytes, key: bytes) -> bytes:
    return Fernet(key).decrypt(token)


def check_encrypt_and_passw_files():
    # Read the encryption key and Mongo Atlas password from the files: KEY_DB.txt, PASSW_DB.txt
    # Update: If this web app deployed to Heroku, this is not the proper way to do it
    # Your file isn't being overwritten by Git; Heroku's filesystem is ephemeral.
    # Any changes made to it will be lost any time the dyno restarts.
    # This happens frequently (at least once per day) whether you deploy or not.
    # Source: https://stackoverflow.com/a/63457968/1970830
    # The proper way is to use an environment variable instead files that are not part of the git repo.
    # The code will try to read environment variables, if failed will still try to read these files
    # (to avoid setting env variables in local machines). And I will keep the streamlit code that will
    # ask for the files to be uploaded if both env variables and files are missing, instead of giving an error,
    # but keep in mind that Heroku dyno will restart within few hours and will ask for these files again
    # if the Heroku OS variables has not been set. See how to setup such env variables and how to read them here:
    # https://stackoverflow.com/a/47949239/1970830

    uploaded_file = None
    try:
        with open('KEY_DB.txt', 'r') as file:
            key = file.read().encode()
            encrypt_key_file_found = True
    except FileNotFoundError:
        encrypt_key_file_found = False

    try:
        with open('PASSW_DB.txt', 'r') as file:
            passw = file.read().replace('\n', '')
            db_password_file_found = True
    except FileNotFoundError:
        db_password_file_found = False

    if encrypt_key_file_found and db_password_file_found:
        main()
    elif not encrypt_key_file_found and db_password_file_found:
        # let's upload encrypt_key_file_found
        uploaded_file = st.file_uploader('Upload the file <KEY_DB.txt> which contains the encryption key.', type='txt',
                                         accept_multiple_files=False, key='111')
    elif encrypt_key_file_found and not db_password_file_found:
        # let's upload db_password_file_found
        uploaded_file = st.file_uploader('Upload the file <PASSW_DB.txt> which contains the password of the MongoDB '
                                         'Atlas online service. ', type='txt', accept_multiple_files=False, key='222')
    else:
        # let's upload both
        uploaded_file = st.file_uploader('Upload both the files <KEY_DB.txt> and <PASSW_DB.txt> which contains the '
                                         'encryption key and the password of the MongoDB Atlas online service. ',
                                         type='txt', accept_multiple_files=True, key='333')

    if uploaded_file is not None and uploaded_file != []:
        if not encrypt_key_file_found and not db_password_file_found:
            for fl in uploaded_file:
                # To convert to a string based IO:
                stringio = StringIO(fl.getvalue().decode("utf-8"))
                # To read file as string:
                string_data = stringio.read()
                with open(fl.name, 'w') as file:
                    file.write(string_data)
            st.experimental_rerun()

        if not encrypt_key_file_found and db_password_file_found:
            stringio = StringIO(uploaded_file.getvalue().decode("utf-8"))
            # To read file as string:
            string_data = stringio.read()
            with open(uploaded_file.name, 'w') as file:
                file.write(string_data)
            st.experimental_rerun()

        if encrypt_key_file_found and not db_password_file_found:
            # To convert to a string based IO:
            stringio = StringIO(uploaded_file.getvalue().decode("utf-8"))

            # To read file as string:
            string_data = stringio.read()
            with open(uploaded_file.name, 'w') as file:
                file.write(string_data)
            st.experimental_rerun()


def load_db(passw, key):
    # Read from MongoDB to Pandas
    lnk = "mongodb+srv://hwasiti:" + passw + "@cluster0.pxlzj.mongodb.net/scraped_data_100_encrypted?retryWrites=true&w=majority"
    client = pymongo.MongoClient(lnk)
    db = client.scraped_data_100_encrypted
    collection = db.scraped_metadata_100_per_search_with_PREDS_encrypted
    df = pd.DataFrame(list(collection.find()))

    print('Database read from Mongo Atlas successfully...')
    df_decrypted = df.copy()

    # Decrypt columns with the sensitive info
    fn = 'df_100_per_search_encrypted.json'
    df.to_json(fn, default_handler=str)  # save the encrypted database as PD for faster access on next runs

    cols_to_decrypt = ['owner name', 'path alias', 'owner', 'exif data']

    for index, row in df_decrypted.iterrows():
        for col in cols_to_decrypt:
            data = df_decrypted.loc[row.name, col]
            df_decrypted.loc[row.name, col] = decrypt(data.encode(), key).decode()
    print('Database decrypted successfully...')
    return df_decrypted


def load_db_from_pd(key):
    fn = 'df_100_per_search_encrypted.json'
    df_encrypted = pd.read_json(open(fn))
    print('Database read from local storage successfully...')

    df_decrypted = df_encrypted.copy()
    cols_to_decrypt = ['owner name', 'path alias', 'owner', 'exif data']

    for index, row in df_decrypted.iterrows():
        for col in cols_to_decrypt:
            data = df_decrypted.loc[row.name, col]
            df_decrypted.loc[row.name, col] = decrypt(data.encode(), key).decode()
    print('Database decrypted successfully...')
    return df_decrypted


def show_images(df_filtered, grid_size, page, captions):
    n_grid_images = grid_size * grid_size  # number of images in a page
    if page * n_grid_images <= len(
            df_filtered):  # if this page will NOT exceed the number of possible images to be shown
        last_y = ceil(n_grid_images / grid_size)
        n_images_to_show = n_grid_images
    else:
        last_img_n = len(df_filtered)
        last_y = ceil((last_img_n - (page - 1) * n_grid_images) / grid_size)
        n_images_to_show = last_img_n - (page - 1) * n_grid_images

    for y in range(last_y):
        cols = st.columns(grid_size)
        last_x = n_images_to_show - (last_y - 1) * grid_size
        for x in range(last_x):
            img_name = df_filtered.filename[(page - 1) * n_grid_images + y * grid_size + x]
            fn = "images_100" + os.sep + img_name
            image = Image.open(fn)
            if image.mode in ("RGBA", "P"):
                image = image.convert('RGB')  # discard the alpha channel
            cols[x].image(image, use_column_width=True)
            for item in captions:
                cols[x].markdown(
                    '**' + item + '**: ' + df_filtered[(df_filtered.filename == img_name)][item].to_string(index=False))
            cols[x].dataframe(df_filtered[(df_filtered.filename == img_name)])


def main(key=None, passw=None):
    if key is None:
        with open('KEY_DB.txt', 'r') as file:
            key = file.read().encode()

    if passw is None:
        with open('PASSW_DB.txt', 'r') as file:
            passw = file.read().replace('\n', '')

    st.set_page_config(
        page_title="Smart Image Scraper",
        page_icon="ðŸ§Š",
        layout="wide",
        initial_sidebar_state="expanded"
    )

    st.title("Smart Image Scraper Results")
    st.write("")

    st.sidebar.title("Settings")
    st.sidebar.header("Grid size")
    grid_size = st.sidebar.slider('', 1, 8, 2)

    columns = ['search term', 'date of download', 'time of download', 'filename', 'link',
               'title', 'description', 'date taken', 'owner name', 'path alias', 'owner',
               'latitude', 'longitude', 'country', 'city', 'machine tags', 'views', 'tags',
               'exif data', 'species prediction score', 'cage prediction score']

    st.sidebar.header("Search term")
    terms_selected = st.sidebar.multiselect('', ['monkey wild', 'monkey cage'], ['monkey wild', 'monkey cage'])

    st.sidebar.header("Metadata")

    captions = st.sidebar.multiselect(
        'Select what to show below images. Other info will be shown as a table below. For long data, just hover the '
        'mouse over it, a tool-tip will show all the cell content.',
        columns)

    st.sidebar.header("DL prediction of Monkey")
    pred_thr_monkey_low, pred_thr_monkey_high = st.sidebar.slider("1.0 = Highly confident", 0.0, 1.0, (0.45, 1.0), 0.05,
                                                                  key='11')  # any rand unique key

    st.sidebar.header("DL prediction of Cage")
    pred_thr_cage_low, pred_thr_cage_high = st.sidebar.slider("", 0.0, 1.0, (0.45, 1.0), 0.05,
                                                              key='12')
    try:
        fn = 'df_100_per_search_encrypted.json'
        with open(fn, 'r') as file:  # Check file available?
            pd_data = file.read()
        df_decrypted = load_db_from_pd(key)
    except FileNotFoundError:
        df_decrypted = load_db(passw, key)

    st.sidebar.header("Country")
    countries = df_decrypted.country.unique().tolist()
    countries_selected = st.sidebar.multiselect('', countries, countries)

    date_max = pd.to_datetime(df_decrypted['date taken'], format='%Y-%m-%d %H:%M:%S').apply(lambda x: x.date()).max()
    date_min = pd.to_datetime(df_decrypted['date taken'], format='%Y-%m-%d %H:%M:%S').apply(lambda x: x.date()).min()
    st.sidebar.header("Date Taken")
    date_low, date_high = st.sidebar.slider("", date_min, date_max, (date_min, date_max))

    view_max = df_decrypted.views.max().astype(int).item()
    view_min = df_decrypted.views.min().astype(int).item()
    st.sidebar.header("View Count")
    view_low, view_high = st.sidebar.slider("", view_min, view_max, (view_min, view_max))

    st.sidebar.header("Search in Metadata")
    search_query = st.sidebar.text_input('Enter below anything to search', value='')

    # Apply the search query
    df_filtered = df_decrypted[
        df_decrypted.apply(lambda row: row.astype(str).str.contains(search_query, case=False).any(), axis=1)]

    # Show Map
    st.sidebar.header("Show Map")
    chk_show_map = st.sidebar.checkbox('')

    # Refresh online database load
    st.sidebar.header("Reload Online DB")
    if st.sidebar.button('Refresh DB'):
        os.remove("df_100_per_search_encrypted.json")  # delete the local DB file
        st.experimental_rerun()

    # filtering the DB
    df_filtered = df_filtered.loc[(df_decrypted['species prediction score'] >= pred_thr_monkey_low)
                                  & (df_decrypted['cage prediction score'] >= pred_thr_cage_low)
                                  & (df_decrypted['species prediction score'] <= pred_thr_monkey_high)
                                  & (df_decrypted['cage prediction score'] <= pred_thr_cage_high)
                                  & (df_decrypted['views'].astype(int) <= view_high)
                                  & (df_decrypted['views'].astype(int) >= view_low)
                                  & (pd.to_datetime(df_decrypted['date taken'], format='%Y-%m-%d %H:%M:%S').apply(
        lambda x: x.date()) <= date_high)
                                  & (pd.to_datetime(df_decrypted['date taken'], format='%Y-%m-%d %H:%M:%S').apply(
        lambda x: x.date()) >= date_low)
                                  & (df_decrypted['search term'].isin(terms_selected))
                                  & (df_decrypted['country'].isin(countries_selected))
                                  ]

    df_filtered.reset_index(drop=True, inplace=True)

    st.markdown('**Total images = ** ' + str(len(df_filtered)))

    col1, col2, col3, col4, col5, col6, col7, col8, col9, col10, col11, col12, col13 = st.columns(
        (1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1))
    total_pages = ceil(len(df_filtered) / (grid_size * grid_size))
    if total_pages == 0:
        total_pages = 1
    pages = ['Page ' + str(i + 1) for i in range(total_pages)]  # number of pages of the gallery

    page = col7.selectbox('', pages)
    current_page = int(page[5:])

    if df_filtered is None:
        st.write("No results to show")
    elif len(df_filtered) == 0:
        st.write("No results to show")
    else:
        show_images(df_filtered, grid_size, current_page, captions)
        # Draw map
        if chk_show_map:
            expand1 = st.beta_expander('Show Map', True)
            df_geo = df_filtered[['search term', 'latitude', 'longitude']][
                (df_filtered['latitude'] != 0) & (df_filtered['longitude'] != 0)]  # ignore those without gps info
            df_geo.reset_index(drop=True, inplace=True)

            expand1.pydeck_chart(pdk.Deck(
                map_style='mapbox://styles/mapbox/light-v9',
                initial_view_state=pdk.ViewState(
                    latitude=0,
                    longitude=0,
                    zoom=1,
                    pitch=50,
                ),

                layers=[
                    pdk.Layer(
                        'HexagonLayer',
                        data=df_geo,
                        get_position='[longitude, latitude]',
                        radius=200,
                        elevation_scale=4,
                        elevation_range=[0, 1000],
                        pickable=True,
                        extruded=True,
                    ),
                    pdk.Layer(
                        'ScatterplotLayer',
                        data=df_geo.loc[(df_geo['search term'] == 'monkey cage')],
                        get_position='[longitude, latitude]',
                        pickable=False,
                        opacity=0.8,
                        stroked=True,
                        filled=True,
                        radius_scale=6,
                        radius_min_pixels=3,
                        radius_max_pixels=100,
                        line_width_min_pixels=1,
                        get_radius="exits_radius",
                        get_fill_color=[255, 0, 0],
                        get_line_color=[255, 0, 0],
                    ),
                    pdk.Layer(
                        'ScatterplotLayer',
                        data=df_geo.loc[(df_geo['search term'] == 'monkey wild')],
                        get_position='[longitude, latitude]',
                        pickable=False,
                        opacity=0.8,
                        stroked=True,
                        filled=True,
                        radius_scale=6,
                        radius_min_pixels=3,
                        radius_max_pixels=100,
                        line_width_min_pixels=1,
                        get_radius="exits_radius",
                        get_fill_color=[0, 255, 0],
                        get_line_color=[0, 255, 0],
                    ),
                ],
            ))
            expand1.write('The map shows the scatter-plot of the datapoints')
            expand1.markdown('* **location** by latitude, longitude coordinates')
            expand1.markdown('* **search term**  by color')
            expand1.write({"monkey wild": "green", "monkey cage": "red"})


# Set these as environment variables and put the encryption key and MongoDB Atlas password in them
# This is especially important if you deploy the web app to Heroku, since it uses ephemeral-filesystem
# https://devcenter.heroku.com/articles/dynos#ephemeral-filesystem
# and dyno will restart at least once a day and deletes all local storage (any file not in git repo will be deleted)
key = os.getenv('SECRET_KEY')
passw = os.getenv('SECRET_PASSWORD')

if key is None or passw is None:
    check_encrypt_and_passw_files()
else:
    main(key, passw)
